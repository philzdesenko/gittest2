{"job":{"components":{"80601":{"id":80601,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-1773186960,"x":0,"y":0,"width":32,"height":32,"inputConnectorIDs":[80605],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Guess Schema"}}}},"visible":true},"2":{"slot":2,"name":"Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"import json\nfrom enum import Enum\nfrom distutils import util as butil\nfrom datetime import datetime as dt\nfrom collections import namedtuple\n\n\nclass IncomparableColumn(Exception):\n    \"\"\"\n    Exception to be raised when trying to compare 2 columns which do not have the same name.\n    For this use case, when we compare columns, we only want to ensure that the DataType is the same.\n    If they are not the same, we can simple take the maximum of the DataType types and use that\n    \"\"\"\n    pass\n\nclass DataType(Enum):\n    \"\"\"\n    DataType is an ordered enumerator type to represent different Snowflake Data Types which\n    are accepted by the Flatten Variant component.\n    Certain Snowflake Data Types are excluded (TIME and DATE)\n    !Order Matters!\n    \"\"\"\n    Unknown = 0\n    Number = 1\n    Float = 2\n    Boolean = 3\n    Timestamp = 4\n    Varchar = 5\n    VariantObject = 6       # format of {key:value, ...} => can be unpacked (by field access (using : operator))\n    VariantArrayObject = 7  # format of [{key:value, ...}, ...] => can be unpacked (requires LATERAL FLATTEN)\n    VariantArrayRaw = 8     # format of [value, ...] => cannot be unpacked (write as VARIANT)\n\n    def __str__(self):\n        if self >= DataType.VariantObject:\n            return \"VARIANT\"\n        return self.name.upper()\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __eq__(self, other):\n        if not isinstance(other, DataType):\n            raise NotImplemented(\"invalid op\")\n        return self.value == other.value\n\n    def __lt__(self, other):\n        if not isinstance(other, DataType):\n            raise NotImplemented(\"invalid op\")\n        return self.value < other.value\n\n    def __gt__(self, other):\n        if not isinstance(other, DataType):\n            raise NotImplemented(\"invalid op\")\n        return self.value > other.value\n\n    def __le__(self, other):\n        if not isinstance(other, DataType):\n            raise NotImplemented(\"invalid op\")\n        return self.value <= other.value\n\n    def __ge__(self, other):\n        if not isinstance(other, DataType):\n            raise NotImplemented(\"invalid op\")\n        return self.value >= other.value\n\n    def valid(self):\n        return self.value > 0\n\n    def is_variant(self):\n        return self >= DataType.VariantObject\n\n\nclass ColumnDef(namedtuple('columnDef', 'DataValue Property Type Alias')):\n    \"\"\"\n    namedtuple like type to hold the attributes of a column within a Variant column.\n    Used for Flatten Variant component on Matillion ETL for Snowflake\n\n    DataValue: placeholder value that will always be \"Data Value\"\n    Property: name of the field in the JSON Response\n    Type: DataType which corresponds to a Snowflake Data Type\n    Alias: Alias of Property\n    \"\"\"\n    def __eq__(self, other):\n        if not isinstance(other, ColumnDef):\n            raise NotImplemented(\"invalid op\")\n        elif self.Property != other.Property:\n            return False # return False here to allow for hashing to work\n        return self.Type == other.Type\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n    def __lt__(self, other):\n        if not isinstance(other, ColumnDef):\n            raise NotImplemented(\"invalid op\")\n        elif self.Property != other.Property:\n            raise IncomparableColumn(\"invalid op\")\n        return self.Type.__lt__(other.Type)\n\n    def __gt__(self, other):\n        if not isinstance(other, ColumnDef):\n            raise NotImplemented(\"invalid op\")\n        elif self.Property != other.Property:\n            raise IncomparableColumn(\"invalid op\")\n        return self.Type.__gt__(other.Type)\n\n    def __le__(self, other):\n        if not isinstance(other, ColumnDef):\n            raise NotImplemented(\"invalid op\")\n        elif self.Property != other.Property:\n            raise IncomparableColumn(\"invalid op\")\n        return self.Type.__le__(other.Type)\n\n    def __ge__(self, other):\n        if not isinstance(other, ColumnDef):\n            raise NotImplemented(\"invalid op\")\n        elif self.Property != other.Property:\n            raise IncomparableColumn(\"invalid op\")\n        return self.Type.__ge__(other.Type)\n\n    def to_grid_record(self):\n        return [self.DataValue, self.Property, self.Type.__str__(), self.Alias]\n\n    def is_variant(self):\n        return self.Type.is_variant()\n\n    def is_expandable_variant(self):\n        return self.Type == DataType.VariantArrayObject or self.Type == DataType.VariantObject\n\n    def to_flatten_definition(self, **kwargs):\n        outer = kwargs.get('outer', 'False')\n        recursive = kwargs.get('recursive', 'False')\n        mode = kwargs.get('mode', 'both')\n        return [ self.DataValue, self.Property, self.Alias, outer, recursive, mode ]\n\ndef NewColumn(name, typ, **kwargs):\n    \"\"\"\n    Constructor for ColumnDef\n    \"\"\"\n    if not typ.valid():\n        raise ValueError(\"Invalid DataType {} for column {}\".format(typ, name))\n\n    alias = name.upper()\n    if name.count(\":\") > 0:\n        alias = name.split(\":\")[-1].upper()\n\n    parent = kwargs.get('parent', variantColumn)\n\n    return ColumnDef(parent, name, typ, alias)\n\nis_ColumnDef = lambda x: isinstance(x, ColumnDef)\n\n\nclass Parsers:\n    \"\"\"\n    Class to hold a series of functions of type:\n        func(value, **kwargs) -> DataType\n\n    Each function returns a specific DataType if the value can be coerced into the DataType,\n    otherwise, DataType.Unknown is returned\n    \"\"\"\n    @staticmethod\n    def variant(val, **kwargs):\n\n        if isinstance(val, dict):\n\n            # TODO: check this logic\n            if val:\n                return DataType.VariantObject\n            # parse empty dict as VARCHAR\n            return DataType.Varchar\n\n        elif isinstance(val, list):\n            if isinstance(val[0], dict):\n                return DataType.VariantArrayObject\n            else:\n                return DataType.VariantArrayRaw\n\n        return DataType.Unknown\n\n    @staticmethod\n    def num(val, **kwargs):\n        try:\n            v = int(val)\n            return DataType.Number\n        except ValueError:\n            return DataType.Unknown\n\n    @staticmethod\n    def float(val, **kwargs):\n        try:\n            v = float(val)\n            return DataType.Float\n        except ValueError:\n            return DataType.Unknown\n\n    @staticmethod\n    def timestamp(val, **kwargs):\n        format = kwargs.get('datetime_format', '%Y-%m-%dT%H:%M:%SZ')\n        try:\n            d = dt.strptime(val, format)\n            return DataType.Timestamp\n        except ValueError:\n            return DataType.Unknown\n\n    @staticmethod\n    def bool(val, **kwargs):\n        try:\n            b = butil.strtobool(val)\n            return DataType.Boolean\n        except ValueError:\n            return DataType.Unknown\n\n    @staticmethod\n    def get_parsers():\n        \"\"\"\n        Returns all the parser functions in a specific order.\n        \"\"\"\n        return [\n        Parsers.variant,\n        Parsers.num,\n        Parsers.float,\n        Parsers.bool,\n        Parsers.timestamp\n        ]\n\nclass ColumnParser:\n    \"\"\"\n    Class to handle the parsing of a ColumnDef using a raw value\n    \"\"\"\n\n    def __init__(self, datetime_fmt = '%Y-%m-%dT%H:%M:%SZ'):\n        self.dt_fmt = datetime_fmt\n\n\n    def parse(self, name, value, **kwargs):\n        \"\"\"\n        Creates a new ColumnDef type with the specified name, the DataType is parsed from the value\n\n         1. Check if the type satisfies a VARIANT data type\n         2. Check if the type can be coerced to an Integer\n         3. Check if the type can be coerced to a Float\n         4. Check if the type can be coerced to a Boolean\n         5. Check if the type can be coerced to a Timestamp\n         6. Assume the type is a VARCHAR\n        \"\"\"\n\n        kw = {\n        'datetime_format': self.dt_fmt\n        }\n\n        typ = DataType.Unknown\n\n        parsers = Parsers.get_parsers()\n\n        for parser in parsers:\n            typ = parser(value, **kw)\n\n            if typ.valid():\n                break\n\n        # if no DataType has been resolved, we must assume that it can be cast as VARCHAR\n        if not typ.valid():\n            typ = DataType.Varchar\n\n        print(\"Column `{}` Value: `{}` => {}\".format(name, value, typ))\n\n        return NewColumn(name, typ, **kwargs)\n\nclass Schema:\n    \"\"\"\n    Class to hold a collection of columns and flattened columns to be used with the Flatten Variant component.\n    \"\"\"\n    def __init__(self, **kwargs):\n        \"\"\"\n        Schema should be initialized using Schema.Guess(...) classmethod rather than directly calling __init__\n        \"\"\"\n        self.datetime_fmt = kwargs.get('datetime_fmt', '%Y-%m-%dT%H:%M:%SZ')\n        self.parser = ColumnParser(self.datetime_fmt)\n\n        # []ColumnDef for column_mappings\n        self.cols = []\n        # []ColumnDef for column_flattens\n        self.flattens = []\n\n    def __str__(self):\n        \"\"\"\n        Returns a format that can be easily copy and pasted into a Grid Variable\n        \"\"\"\n        cols = \"\\n\".join(\n        [ \"\\t\".join(c.to_grid_record()) for c in self.cols ]\n        )\n        flattens = \"\\n\".join(\n        [\n            \"\\t\".join(map(str,c.to_flatten_definition())) for c in self.flattens\n        ]\n        )\n\n        msg = \"Columns:\\n{}\\nFlattens:\\n{}\".format(cols, flattens)\n\n        return msg\n\n    def parse(self, name, value, **kwargs):\n        return self.parser.parse(name, value, **kwargs)\n\n    def column_mappings(self, grid_variable = None):\n        \"\"\"\n        Returns a grid-like (list of list) variable which can be used in the `Column Mapping`\n        field of the METL for Snowflake Flatten Variant Component\n\n        If grid_variable is not None, update the specified Grid Variable\n\n        format = [\n        [`columnName`, `property`, `type`, `alias`],\n        ...\n        ]\n        \"\"\"\n        res = [\n            c.to_grid_record() for c in self.cols\n        ]\n\n        if grid_variable:\n            context.updateGridVariable(grid_variable, res)\n\n        return res\n\n    def column_flattens(self, grid_variable = None):\n        \"\"\"\n        Returns a grid-like (list of list) variable which can be used in the `Column Flattens`\n        field of the METL for Snowflake Flatten Variant Component\n\n\t\tIf grid_variable is not None, update the specified Grid Variable\n\n        format = [\n        [`columnName`, `property`, `alias`, `outer`, `recursive`, `mode`],\n        ...\n        ]\n        \"\"\"\n        res = [\n            c.to_flatten_definition() for c in self.flattens\n        ]\n\n        if grid_variable:\n            context.updateGridVariable(grid_variable, res)\n\n        return res\n\n    def decode(self, row):\n        \"\"\"\n        Args:\n\n        : row (dict) - collection of key/value pairs that are to be unpacked into \n        column mappings and flattens. \n        \"\"\"\n\n        mappings = []\n        flattens = []\n\n        for k, v in row.items():\n            mappings, flattens = self._decode_key_value(k, v, mappings, flattens)\n\n        self.update_flattens(*flattens)\n        self.update_cols(*mappings)\n\n\n    def _decode_key_value(self, key, value, mappings = [], flattens = [], **kwargs):\n\n        col_def = self.parse(key, value, **kwargs)\n\n        if not col_def.is_expandable_variant():\n            mappings.append(col_def)\n\n        elif col_def.Type == DataType.VariantObject:\n            mappings, flattens = self._decode_struct(key, value, mappings, flattens, **kwargs)\n\n        elif col_def.Type == DataType.VariantArrayObject:\n            mappings, flattens = self._decode_array_struct(key, value, mappings, flattens, **kwargs)\n\n        return mappings, flattens\n\n    def _decode_struct(self, key, struct, mappings = [], flattens = [], source = None, **kwargs):\n        \"\"\"\n        Decodes DataType.VariantObject types.\n        Returns (mappings []ColumnDef, flattens []ColumnDef)\n\n        Args:\n\n        : key (str) - the parent key containing the struct\n        : struct (dict) - the JSON data to be decoded\n        : mappings ([]ColumnDef) - mappings to be recursively built\n        : flattens ([]ColumnDef) - flattens to be recursively built\n        : source (str, DEFAULT = None) - the source of the struct if it has been flattened\n\n        \"\"\"\n        print(\"Decoding Struct: {}\".format(key))\n\n        parent = kwargs.get('parent', None)\n        for k, v in struct.items():\n            new_key = k\n\n            if key:\n                new_key = \"{}:{}\".format(key, k)\n\n\n            if source:\n                kwargs.update({\n                'parent': source.upper()\n                })\n\n            mappings, flattens = self._decode_key_value(new_key, v, mappings, flattens, **kwargs)\n\n        return mappings, flattens\n\n    def _decode_array_struct(self, key, array_struct, mappings = [], flattens = [], **kwargs):\n        \"\"\"\n        Decodes DataType.VariantArrayObject types.\n        Returns (mappings []ColumnDef, flattens []ColumnDef)\n\n        Args:\n\n        : key (str) - the parent key containing the struct\n        : struct (dict) - the JSON data to be decoded\n        : mappings ([]ColumnDef) - mappings to be recursively built\n        : flattens ([]ColumnDef) - flattens to be recursively built\n        : source (str, DEFAULT = None) - the source of the struct if it has been flattened\n        \"\"\"\n        print(\"Decoding Array: {}\".format(key))\n\n        new_key = key\n        if key.count(\":\") > 0:\n            kwargs.update({\n            # second last should be the parent and we want the alias (i.e. the upper case version)\n            'parent': key.split(\":\")[-2].upper()\n            })\n            new_key = key.split(\":\")[-1]\n\n        flatten_col = NewColumn(new_key, DataType.VariantArrayObject, **kwargs)\n\n        flattens.append(flatten_col)\n\n        for row in array_struct:\n            mappings, flattens = self._decode_struct(None, row, mappings, flattens, key, **kwargs)\n\n        return mappings, flattens\n\n\n\n    def extract_cols_from_variant(self, record, name = None, **kwargs):\n        cols = []\n\n        namer = lambda x: x\n\n        if name:\n            namer = lambda x: \"{}:\".format(name) + x\n\n        for key, value in record.items():\n\n            col_def = self.parse(namer(key), value, **kwargs)\n\n            cols.append(col_def)\n\n        return cols\n\n\n    @staticmethod\n    def update_list(target, *data):\n        \"\"\"\n        Given a target (list) and some new data\n        For each data element:\n        + Check if it is already within target, if it is, replace the old value\n            with the new value if the new value is 'greater' than the old\n        + Otherwise, add the element to the target list\n        \"\"\"\n        for new in data:\n\n            if new in target:\n                i = target.index(new)\n\n                old = target[i]\n\n                if new > old:\n                    target[i] = new\n            else:\n                target.append(new)\n\n    def update_cols(self, *cols):\n        self.update_list(self.cols, *cols)\n\n    def update_flattens(self, *cols):\n        self.update_list(self.flattens, *cols)\n\n\n    @classmethod\n    def Guess(cls, *records, **kwargs):\n        \"\"\"\n        Given a number of records, attempt to decode the schema from each row iteratively.\n        More records will make this more accurate, but will result in decreased performance.\n        \"\"\"\n        print(\"Attempting to parse schema using {} rows\".format(len(records)))\n\n        schema = cls(**kwargs)\n\n        for record in records:\n            r = json.loads(record)\n            schema.decode(r)\n\n        return schema\n      \nkwargs = {\n  'datetime_format': datetimeFormat\n}\n\n# convert the previously collected sample into a list of raw JSON string\nsamples = [ x[0] for x in context.getGridVariable('dataSample') ]\n\nschema = Schema.Guess(*samples, **kwargs)\n\nprint(\"Guessed Schema:\\n{}\".format(schema))\n\n_ = schema.column_flattens(grid_variable = 'columnFlattens')\n_ = schema.column_mappings(grid_variable = 'columnMappings')\n\n## For debugging purposes\n#def print_grid(x):\n#  print(x)\n#  for y in context.getGridVariable(x):\n#    print(y)\n#    \n#print_grid('columnFlattens')\n#print_grid('columnMappings')\n"}}}},"visible":true},"3":{"slot":3,"name":"Interpreter","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Python 3"}}}},"visible":true},"4":{"slot":4,"name":"Timeout","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"INTEGER","value":"360"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"80602":{"id":80602,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-1773186960,"x":-159,"y":159,"width":32,"height":32,"inputConnectorIDs":[80606],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Error"}}}},"visible":true},"2":{"slot":2,"name":"Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"msg = \\\n\"\"\"\nUnable to sample data from {}.{}.{} \n\nError: {}\n\nAttempted SQL:\n{}\n\"\"\".format( sourceDatabase, sourceSchema, sourceTableName, errorMessage, sampleDataSQL)\n\n# export error to higher level Jobs if needed\ncontext.updateVariable('errorMessage', msg)\n\nraise Exception(msg)"}}}},"visible":true},"3":{"slot":3,"name":"Interpreter","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Python 3"}}}},"visible":true},"4":{"slot":4,"name":"Timeout","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"INTEGER","value":"360"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"80603":{"id":80603,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":1155583855,"x":-160,"y":0,"width":32,"height":32,"inputConnectorIDs":[80604],"outputSuccessConnectorIDs":[80605],"outputFailureConnectorIDs":[80606],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{"1":{"slot":1,"fromId":null,"fromName":"Message","mapTo":"errorMessage"}},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Sample N Rows"}}}},"visible":true},"2":{"slot":2,"name":"Basic/Advanced","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Advanced"}}}},"visible":true},"3":{"slot":3,"name":"Database","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"[Environment Default]"}}}},"visible":false},"4":{"slot":4,"name":"Target Table","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":""}}}},"visible":false},"6":{"slot":6,"name":"Table Columns","elements":{},"visible":false},"7":{"slot":7,"name":"SQL Query","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"${sampleDataSQL}"}}}},"visible":true},"8":{"slot":8,"name":"Grid Variable","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"dataSample"}}}},"visible":true},"9":{"slot":9,"name":"Grid Variable Mapping","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"JSON_PROJECT"}}}},"visible":true},"10":{"slot":10,"name":"Limit","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"INTEGER","value":"100"}}}},"visible":false},"11":{"slot":11,"name":"Order By","elements":{},"visible":false},"12":{"slot":12,"name":"Sort","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Ascending"}}}},"visible":false},"13":{"slot":13,"name":"Filter Conditions","elements":{},"visible":false},"14":{"slot":14,"name":"Combine Conditions","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"AND"}}}},"visible":false},"20":{"slot":20,"name":"Schema","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"[Environment Default]"}}}},"visible":false}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"80648":{"id":80648,"inputCardinality":"ZERO","outputCardinality":"MANY","connectorHint":"UNCONDITIONAL","executionHint":"FLOW","implementationID":444132438,"x":-480,"y":0,"width":32,"height":32,"inputConnectorIDs":[],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[80607],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Begin"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"80650":{"id":80650,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-1773186960,"x":-320,"y":0,"width":32,"height":32,"inputConnectorIDs":[80607],"outputSuccessConnectorIDs":[80604],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{"1":{"slot":1,"fromId":null,"fromName":"Message","mapTo":"errorMessage"}},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Set Sample SQL"}}}},"visible":true},"2":{"slot":2,"name":"Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"q = \\\n\"\"\"\nSELECT TOP {} \"{}\" FROM \"{}\".\"{}\".\"{}\"\n\"\"\".format(rowScanDepth, variantColumn, sourceDatabase, sourceSchema, sourceTableName)\n\ncontext.updateVariable('sampleDataSQL', q)\n\nprint(\"`sampleDataSQL`:\\n{}\".format(sampleDataSQL))"}}}},"visible":true},"3":{"slot":3,"name":"Interpreter","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Python 3"}}}},"visible":true},"4":{"slot":4,"name":"Timeout","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"INTEGER","value":"360"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]}},"successConnectors":{"80604":{"id":80604,"sourceID":80650,"targetID":80603},"80605":{"id":80605,"sourceID":80603,"targetID":80601}},"failureConnectors":{"80606":{"id":80606,"sourceID":80603,"targetID":80602}},"unconditionalConnectors":{"80607":{"id":80607,"sourceID":80648,"targetID":80650}},"trueConnectors":{},"falseConnectors":{},"iterationConnectors":{},"noteConnectors":{},"notes":{"80649":{"id":80649,"x":-953,"y":-75,"width":389,"height":147,"text":"**Description**\n\nQuery a Snowflake Table with a Variant Data Type column to be flattened to get a number of samples of the struct.\n\nAttempt to guess the structure of the Variant column - the guess is exported in the __columnMapping__ and __columnFlattens__ grid variables, which are intended to be passed into the Flatten Variant component.","colour":"00ce4f"}},"variables":{"datetimeFormat":{"definition":{"name":"datetimeFormat","type":"TEXT","scope":"BRANCH","description":"Datetime format to be used when trying to check if a particular value is a TIMESTAMP Data Type.","visibility":"PUBLIC"},"value":"%Y-%m-%dT%H:%M:%SZ"},"errorMessage":{"definition":{"name":"errorMessage","type":"TEXT","scope":"TASKBATCH","description":"Exported Variable - do not set a value. \nIf the job fails, this will be populated with a relevant error message.","visibility":"PUBLIC"},"value":""},"rowScanDepth":{"definition":{"name":"rowScanDepth","type":"DECIMAL","scope":"BRANCH","description":"How many rows should be sampled when attempting to guess the schema of the Variant type.\nIncreasing this value will make the guess more accurate, at the cost of performance.\nDefault is 5.","visibility":"PUBLIC"},"value":"5"},"sampleDataSQL":{"definition":{"name":"sampleDataSQL","type":"TEXT","scope":"BRANCH","description":"","visibility":"PRIVATE"},"value":null},"sourceDatabase":{"definition":{"name":"sourceDatabase","type":"TEXT","scope":"BRANCH","description":"Snowflake Database containing the table to be flattened.","visibility":"PUBLIC"},"value":"[Environment Default]"},"sourceSchema":{"definition":{"name":"sourceSchema","type":"TEXT","scope":"BRANCH","description":"Snowflake Schema containing the table to be flattened.","visibility":"PUBLIC"},"value":"[Environment Default]"},"sourceTableName":{"definition":{"name":"sourceTableName","type":"TEXT","scope":"BRANCH","description":"Snowflake Table containing the raw extract data table.\nThis table is expected at least 1 Variant column which is intended to be expanded.","visibility":"PUBLIC"},"value":"[Environment Default]"},"variantColumn":{"definition":{"name":"variantColumn","type":"TEXT","scope":"BRANCH","description":"Name of the VARIANT type column in the source table to be flattened.\nDefault is Data Value.","visibility":"PUBLIC"},"value":"Data Value"}},"grids":{"columnFlattens":{"definition":{"name":"columnFlattens","scope":"TASKBATCH","definitions":[{"name":"columnName","type":"TEXT"},{"name":"propertyName","type":"TEXT"},{"name":"propertyAlias","type":"TEXT"},{"name":"outer","type":"TEXT"},{"name":"recursive","type":"TEXT"},{"name":"mode","type":"TEXT"}],"description":"Exported Variable - do not set a value for this.\nDescribes how columns/properties should be flattened according to the Matillion ETL for Snowflake Flatten Variant Component.","visibility":"PUBLIC"},"values":[]},"columnMappings":{"definition":{"name":"columnMappings","scope":"TASKBATCH","definitions":[{"name":"dataValue","type":"TEXT"},{"name":"propertyName","type":"TEXT"},{"name":"propertyType","type":"TEXT"},{"name":"propertyAlias","type":"TEXT"}],"description":"Exported Variable - do not set a value for this.\nDescribes how columns/properties should be mapped according to the Matillion ETL for Snowflake Flatten Variant Component.","visibility":"PUBLIC"},"values":[]},"dataSample":{"definition":{"name":"dataSample","scope":"BRANCH","definitions":[{"name":"DataValue","type":"TEXT"}],"description":"Grid Variable to store N samples from the source table.","visibility":"PRIVATE"},"values":[{"values":["{   \"Cases\": 0,   \"City\": \"\",   \"CityCode\": \"\",   \"Country\": \"United Kingdom\",   \"CountryCode\": \"GB\",   \"Date\": \"2020-01-22T00:00:00Z\",   \"Lat\": \"-51.8\",   \"Lon\": \"-59.52\",   \"Province\": \"Falkland Islands (Malvinas)\",   \"Status\": \"confirmed\" }"]},{"values":["{   \"Cases\": 1,   \"City\": \"\",   \"CityCode\": \"\",   \"Country\": \"United Kingdom\",   \"CountryCode\": \"GB\",   \"Date\": \"2020-01-23T00:00:00Z\",   \"Lat\": \"-51.8\",   \"Lon\": \"-59.52\",   \"Province\": \"Falkland Islands (Malvinas)\",   \"Status\": \"confirmed\" }"]},{"values":["{   \"Cases\": 1,   \"City\": \"\",   \"CityCode\": \"\",   \"Country\": \"United Kingdom\",   \"CountryCode\": \"GB\",   \"Date\": \"2020-01-23T00:00:00Z\",   \"Lat\": \"-51.8\",   \"Lon\": \"-59.52\",   \"Province\": \"Falkland Islands (Malvinas)\",   \"Status\": \"confirmed\", \"demo\": {\"key\": \"value\"} }"]}]}}},"info":{"name":"Variant - Detect Schema","description":"Unpacked from Shared Job [Flatten and Load].","type":"ORCHESTRATION","tag":"c572dc3a-ecb9-45eb-b9ce-66f1c50f16bc"}}